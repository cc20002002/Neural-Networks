\section{Conclusion}
In conclusion, our numerical simulation supports the theoretical results that \textsc{nmf} based on objective function~\eqref{eq:obnmf} is more robust to Gaussian noise and \textsc{klnmf} based on objective function~\eqref{eq:klobj} is more robust to Poisson noise. The two algorithms have a similar performance against Pepper \& Salt noise. However, the \textsc{nmf} algorithm reconstructs image better without noise and converges much faster with the multiplicative update rule when comparing with \textsc{klnmf}. Also, simulation results find both of the multiplicative update rules are sensitive to the initial values of matrices~$W$ and~$H$. Section~\ref{chapter2} proposes a solution based on parallel programming to solve this problem. However, this solution requires high performance computer so that the algorithm converges in a reasonable amount of time.

Recently, \textsc{nvidia} released their \href{https://developer.nvidia.com/cuda-zone}{\texttt{Cuda}} package which parallelises algorithms using \textsc{gpu}. This package improves the speed of parallelisable algorithms, including many \textsc{nmf} algorithms, by a factor of $>100$. As a computationally expensive procedure, our suggestion of using multiple initialisations will be more novel if a \textsc{gpu} version based on \href{https://developer.nvidia.com/cuda-zone}{\texttt{Cuda}} could be designed. 