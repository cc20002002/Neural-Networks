\section{Introduction\label{chapter1}}
%Briefly introduce \textsc{nmf}, applications

%- Whatâ€™s the aim of the study? 
% Draft Completed - Pending Review
The aim of this study is to build a multi-layer neural network application to perform a multi-class classification and use various optimisation approaches to improve the prediction accuracy on the given dataset.
The task provides a training dataset and a testing dataset,
the training dataset given for this task consists of 128 features for 60,000 samples,
the test dataset contains 10,000 samples with same amount of features as training dataset,
Given the naive multi-layer neural network implementation in the early stage of our research,
we also tried various optimisation methodologies to further improve the prediction accuracy,
these methods include different activation functions, weight decay, stochastic gradient descent methods, mini-batch training, batch normalisation and dropout.

% - Why is the study important? 
As we all know a Neural Network is a computational learning system that uses a network of functions in multiple layers to understand and translate a data input of one form into a desired output,
usually in another form (\citet{DeepAI}).
It learns from processing many labelled examples that are supplied during training and using this answer key to learn what non-linear and complex characteristics of the input are needed to construct the correct output.
In this supervised training,
a network processes the inputs and compares its actual outputs against the expected outputs.
For each iteration the cost will be propagated back through the network,
to adjust the weights in each layer.
This process is repeated until the best accuracy is achieved;
This supervised learning algorithm is often referred to as a back-propagation algorithm,
which is useful for training multi-layer Neural Networks.
Since Neural Networks have shown a performance breakthrough in the area of object detection and scene classification,
so this study will focus on identifying the best network and optimisation methodologies for this purpose (\citet{lecun1998Gradient}).

% Draft Completed - Pending Review
In this report, we will first introduce all these optimisation methodologies and their common usages,
followed by the experiment setup and results for the research as well as a detailed comparison of results by applying various methodologies.
In the end we will also discuss importance of all these methodologies and how our neural network model benefits from them.

%Non-negative matrix factorisation (\textsc{nmf}) is a matrix decomposition technique that approximates a data matrix with non-negative entries with the multiplication of two non-negative matrices
%\begin{equation*}
%  V \approx WH.
%\end{equation*}
%In this approximation, matrix~$W$ is the basis, and matrix~$H$ is the weight matrix corresponding to the %new dictionary~$W$. \textsc{nmf}
%is applicable to an extensive range of domain. For example, \citet{lee1999learning} suggest that \textsc{nmf} is useful for image processing problems including facial recognition.

%Matrices~$W$ and~$H$ are often referred as the basis images and weights, 
%because the observed image $V$ is approximated by a linear combination of~$W$ with positive %coefficients~$H$.
%Due to the additive nature of the algorithm, the dictionary~$W$ are often parts of images that are easily interpretable.
%This property also distinguishes \textsc{nmf} from other traditional image processing methods such as principal components analysis (\textsc{pca}).
%\citet{guillamet2002non} demonstrate that \textsc{nmf} performs better in image classification problems in comparison with \textsc{pca}.
%Moreover, \textsc{nmf} is also applicable to text mining such as semantic analysis.
%Generally, \textsc{nmf} is useful to discover semantic features of an article by counting the frequency of each word, and then approximating the document from a subset of a large array of features \citep{lee1999learning}.

%In practice, face images could be easily corrupted during data collection by noise with large magnitude. Corruption may result from lighting environment, facial expression or facial details. An \textsc{nmf} algorithm that is robust to large noise is desired for the real-world applications. Therefore, the objective of this project is to analyse the robustness of \textsc{nmf} algorithms on corrupted datasets. We implement two \textsc{nmf} algorithms proposed by \citet{lee2001algorithms} on real face image datasets, \texttt{ORL} dataset and the \texttt{CroppedYale} dataset. We add artificial noises to the face images are contaminated. We then apply nonparametric statistical methods to analyse the robustness of these two algorithms from simulation results.

%The rest of the report is organized as follows. We describe noisy design and two \textsc{NMF} algorithms including Euclidean Distance and Kullback-Leibler Divergence (\textsc{KLD}) in Section 2. Section 3 shows experiment setup and empirical results which demonstrate the robustness of the two NMF algorithms. The conclusions and future work are discussed in Section 5.
